= So How Do I Build a Local Development Environment?

Building a development environment which mirrors production (or any other environment) hasn't, historically, been an easy task.
But with Docker, it's become, _almost_, trivial.
So in this chapter, I'll step you through how to use Docker to setup a local development environment for developing your PHP applications.
All being well, you’ll be up and running in less than 20 minutes. 

Let's get started!

== Our Demo Application

The demo application that we’ll use throughout this book, as I mentioned earlier, is based on the Mezzio framework.
It’s not that sophisticated, rather a simplistic application that needs to interact with a database; rather the classic PHP application, if you will.
It doesn’t make use of any logging, queueing, or caching services.
I decided to keep the requirements rather modest, so that it didn’t get in the way of the book’s main purpose.
So, the application needs three core services:

. A PHP runtime
. A webserver to serve the static content.
  It will need a decent one.
  For that, I've chosen NGINX over Apache.
. A database server to provide the dynamic information.
  For that, I've chosen PostgreSQL.

There will also be a couple of PHP extensions required, but we can cover them shortly.

Given these needs, the setup will be composed of three containers:

- One container for PHP
- One container for NGINX; and
- One container for PostgreSQL

TIP: This follows the Docker ethos of https://docs.docker.com/config/containers/multi-service_container/[one process (or service) per container].
The essential setup can be visualized in the illustration below.

In addition the setup will create two networks: one internal one and one public one.
The PHP, NGINX, and database containers will be placed within the internal one, so that they can communicate freely with one another. 
The NGINX container will be placed within the public one.

I’m doing this for two reasons:

. To give a quick introduction to http://docs.docker.oeynet.com/compose/networking/[networking within Docker]; and
. To add a bit of http://docs.docker.oeynet.com/engine/security/security/[security] to the Docker setup. 
  The setup will allow only a minimum of access from the outside to the resources of the configuration.

// Cover shared volumes, environment variables, healthcheck, labels, secrets, restart
lastly, port 80 on NGINX container will be connected to (http://docs.docker.oeynet.com/compose/compose-file/#expose[exposed]) port 8080 on the local machine (or host), so that the application can be used.

The essential setup can be visualized in the illustration below.

image::docker-design.png[The Docker Container Setup]

Let's start with the web server configuration.
In the root directory of your project, create a new file, called `docker-compose.yml`.
In there, add the following configuration:

[source,yaml]
----
version: '3'

volumes:
  database_data:
    driver: local

services:
  nginx:
    image: nginx:latest
    ports:
      - 8080:80
    volumes:
      - ./docker/nginx/default.conf:/etc/nginx/conf.d/default.conf
    volumes_from:
      - php
----

The configuration starts off by specifying that we're using https://docs.docker.com/compose/compose-file/#/version-2[version 2 of the Docker Compose file format].
This is important as using version 2 requires less work on our part, in comparison with version 1.

It next sets up http://container-solutions.com/understanding-volumes-docker/[a persistable filesystem volume], which will be used later in the PostgreSQL container.
This is important to be aware of as, by default, filesystems in a Docker container are setup to be read-only.

Given that, any changes made aren't permanent.
When a container restarts, the original files will be restored and any new files will be removed.
Not a great thing when working with databases, or other storage mechanisms.

We next define an element called `services`.
This element lists the definitions of the three containers which will make up our build, and start defining the NGINX container.

What this does is to create a container called `nginx`, which can be referred to by the other containers using the hostname `nginx`.
It will use the latest, official, Docker NGINX container image as the base for the container.
After that, we map port 80 in the container to port 8080 on our host machine.
This way, when we're finished, we'll be able to access our application by navigating to `+http://localhost:8080+`.

It next copies `./docker/nginx/default.conf` from the local filesystem to `/etc/nginx/conf.d/default.conf` in the container's filesystem.
default.conf provides the core configuration for NGINX.
To save space, I've not included it here.
However, you can find it https://raw.githubusercontent.com/settermjd/docker-for-local-development/master/docker/nginx/default.conf[in the repository for this tutorial].

Finally, the container gets access to a filesystem volume in the PHP container, which we'll see next.
This will let us develop locally on our host machine, yet use the code in the NGINX server.

== The PHP Container

The configuration for the PHP container, below, is rather similar to that of the NGINX container.

[source,yaml]
----
php:
  build: ./docker/php/
  expose:
    - 9000
  volumes:
    - .:/var/www/html
----

You can see that it starts off by naming the container `php`, which sets the container's hostname.
The `build` directive tells it to use a configuration file, called `Dockerfile`, located in `./docker/php` which contains the following instructions:

[source,yaml]
----
FROM php:7.0-fpm

RUN docker-php-ext-install pdo_mysql \
    && docker-php-ext-install json
----

This states that our container is based on the official PHP 7 image from Docker Hub, which uses PHP-FPM.
I'm keeping things as official as possible.

In addition to using the default image, I've also added some PHP extensions, by calling the `docker-php-ext-install` command.
Specifically, I'm ensuring that `pdo_mysql` and `json` are available in the container.

NOTE: This command does not install an extension's dependencies.
It only installs the extension, if the dependencies are available.

Going back to docker-compose.yml, it next exposes the container's port 9000.
If this is your first time reading about Docker, that might not make a lot of sense.
What it's doing is exposing the container's port 9000, a lot like when we allow access to a port through a firewall.

If you've had a look at `./docker/nginx/default.conf` in the source repository, you'll have see that it contains the directive: `fastcgi_pass php:9000;`.
This allows the NGINX container to pass off requests to PHP in the PHP container.

Lastly, we're mapping a directory on our development machine to a directory in the container, for use in the container.
This will also be available in the NGINX container, thanks to the `volumes_from` directive, which we saw earlier.

This has the effect of sharing your local directory with the container, rather like https://www.vagrantup.com/docs/synced-folders/[Vagrant's shared folders], which makes local development quite efficient.
When you make a change in your development environment, whether in a text editor, or an IDE such as PhpStorm, the changes will be available in the container as well.
There is no need to manually copy or sync files between your development environment and the container.

== The PostgreSQL Server

Now, for the final piece, the PostgreSQL container.

[source,yaml]
----
mysql:
  image: mysql:latest
  expose:
    - 3306
  volumes:
    - database_data:/var/lib/mysql
  environment:
    MYSQL_ROOT_PASSWORD: secret
    MYSQL_DATABASE: project
    MYSQL_USER: project
    MYSQL_PASSWORD: project
----

As with the other containers, we've given it a name (and hostname): `mysql`.
We are using the official PostgreSQL container image, from https://hub.docker.com/[DockerHub] as the foundation for it and exposing port 3306, the standard PostgreSQL port, which was referred to in the PHP container.

Next, using the `volumes` directive, we're making any changes in `/var/lib/mysql`, where PostgreSQL will store its data files, permanent.
We then finish up setting four environment variables, which the PostgreSQL server needs.
These are for the root PostgreSQL password, the name of the database to create, and an application username and password.

== Booting the Docker Containers

Now that we've configured the containers let's make use of them.
From the terminal, in the root directory of your project, run the following command:

----
docker-compose up -d
----

What this will do, is to look for `docker-compose.yml` in the same directory for the instructions it needs to build the containers, and then start them.
After they start, Docker will go into daemon mode.

When you run this, you'll see each container being created and started.
If this is the first time that you've created and launched the containers, then the base images will have to be first downloaded, before the containers can be created on top of them.

This may take a few minutes, based on the speed of your connection.
However, after the first time, they'll usually be booted in under a minute.

With them created, you're ready to use them.
At this point, in a browser, navigate to `http://localhost:8080`, where you'll see your application running, which renders https://matthewsetter.com/zend-expressive-introduction[the standard Zend Expressive Skeleton Project home page].

== Chapter Recap

That's how to use Docker to build a local development environment for Zend Expressive (or any PHP) application.
We have one container which runs PHP, one which runs NGINX, and one which runs PostgreSQL;
all able to talk to each other as needed.

You could say that we can now build environments a lot like we can build code—in a modular fashion.
It's a fair way of thinking about it.
Why shouldn't we be able to do so?

I appreciate this has been quite a rapid run-through.
But it has covered the basics required to get you started.
We haven't looked too deeply into how Docker works, nor gone too far beyond the basics.
