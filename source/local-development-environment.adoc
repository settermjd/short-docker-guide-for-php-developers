= So How Do I Build a Local Development Environment?

Building a development environment which mirrors production (or any other environment) hasn't, historically, been an easy task.
But with Docker, it's become, _almost_, trivial.
So in this chapter, I'll step you through how to use Docker to setup a local development environment for developing your PHP applications.
All being well, you’ll be up and running in less than 20 minutes. 

Let's get started!

== Our Demo Application

The demo application that we’ll use throughout this book, as I mentioned earlier, is based on https://docs.mezzio.dev/mezzio/[the Mezzio framework].
It’s not that sophisticated an application, rather it’s a simplistic one that needs to interact with a database. 
It doesn’t make use of any logging, queueing, or caching services.
A "_classic_" PHP application - old school even - if you will.

I decided to keep the requirements rather modest, so that it didn’t distract from the book’s main purpose.
That said, the application needs three core services for it to function:

. A PHP runtime. 
  I’ll be using PHP {php-runtime-version}.
. A webserver to serve the static content.
  I've chosen NGINX instead of Apache.
. A database server to provide the dynamic information.
  For that, I've chosen PostgreSQL.

There will also be a couple of PHP extensions required, which we’ll cover shortly.
Given these needs, the setup will be composed of three containers:

- One container for PHP
- One container for NGINX; and
- One container for PostgreSQL

TIP: This follows the Docker ethos of https://docs.docker.com/config/containers/multi-service_container/[one process (or service) per container].
The essential setup can be visualized in the illustration below.

.The basic Docker setup overview
image::docker-design.png[]

In addition the setup will create two networks: one internal one and one public one.
The PHP, NGINX, and database containers will be placed within the internal one, so that they can communicate freely with one another. 
The NGINX container, however, as we need to make requests to it, will also be placed within the public network.

I’m doing this for two reasons:

. To give a quick introduction to http://docs.docker.oeynet.com/compose/networking/[networking within Docker]; and
. To add a bit of http://docs.docker.oeynet.com/engine/security/security/[security] to the Docker setup. 
  The setup will allow only a minimum of access from the outside to the resources of the configuration.

// TODO: Cover shared volumes healthcheck, labels, secrets
Lastly, port 80 on the NGINX container will be connected to (http://docs.docker.oeynet.com/compose/compose-file/#expose[exposed]) port 8080 on the local machine (or host), so that the application can be used.

== The Docker Compose Configuration

With the design out of the way, let’s get started working through the configuration file, starting with the web server container.
In the root directory of your project, create a new file, called `docker-compose.yml`.
In that file, add the following configuration:

[source,yaml]
----
version: '3'

volumes:
  database_data:
    driver: local

services:
  nginx:
    image: nginx:latest
    restart: always
    ports:
      - 8080:80
    volumes:
      - ./docker/nginx/default.conf:/etc/nginx/conf.d/default.conf
      - ./:/var/www/html
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/ping"]
      interval: 60s
      timeout: 3s
      retries: 3
----

=== The File Version

The configuration starts off by specifying that we're using https://docs.docker.com/compose/compose-file/#/version-3[version 3 of the Docker Compose file format].
It next sets up http://container-solutions.com/understanding-volumes-docker/[a persistable filesystem volume], which will be used later in the PostgreSQL container.
This is important to be aware of as, by default, filesystems in a Docker container are setup to be read-only.

Given that, any changes made aren't permanent.
When a container restarts, the original files will be restored and any new files will be removed.
Not a great thing when working with databases, or other storage mechanisms.

=== Service Configuration

We next define an element called `services`.
This element lists the definitions of the three containers which will make up our build, and start defining the NGINX container (or service).

What this does is to create a container called `nginx`, which can be referred to by the other containers using the hostname `nginx`.

[WARNING]
====
You can use the `container_name` directive to set a custom name as well. 
However, https://docs.docker.com/compose/compose-file/compose-file-v3/#container_name[according to the Docker documentation]: 

> "_Because Docker container names must be unique, you cannot scale a service beyond 1 container if you have specified a custom name._" 

Please be aware of that.
====

It will use the latest, official, https://registry.hub.docker.com/_/nginx[Docker NGINX image] as the base for the container.
Next, it sets the `restart` directive to `always`.
This will cause Docker to restart it if it should crash or stop for some reason, other than when running `docker-compose down`.
This directive supports three additional values:

[cols="25%,75%"]
|===
|`no` 
|This is the default value. When set, Docker does not restart a container for any reason. 
|`on-failure`
|When set Docker restarts a container if the exit code indicates an on-failure error.
|`unless-stopped`
|When set Docker always restarts a container, except when the container is stopped (manually or otherwise).
|===

After that, it maps port 80 in the container to port 8080 on our host machine.
This way, we'll be able to access the application by navigating to `http://localhost:8080`.

It next copies `./docker/nginx/default.conf` from the local filesystem to `/etc/nginx/conf.d/default.conf` in the container's filesystem.
`default.conf` provides the core configuration for NGINX.

[source,php,linenos,indent=0]
----
include::https://raw.githubusercontent.com/settermjd/docker-for-local-development/master/docker/nginx/default.conf[in the repository for this tutorial]
----

Finally, the current directory is mounted in the container at `/var/www/html`.
This lets us develop locally on our host machine, yet use the code in the NGINX container.

==== Health Checks

The last configuration for this container is to add https://docs.docker.com/engine/reference/builder/#healthcheck[a health check].
What these do is determine whether or a container s considered "healthy", or needs to be restarted.
Healthchecks can be whatever you want them to be.
In the case of this service, by default, unless you remove it, Mezzio applications come with a ping endpoint.

This endpoint returns a JSON response containing the current timestamp.
It’s a simplistic way of testing if the application is still working.
So, the healthcheck will make a cURL request to that endpoint every 60 seconds, and allow for a 3 second timeout.
If four attempts to the endpoint fail, then the container is considered “unhealthy” and will be restarted.

Here’s how to test that a health check is working.

----
docker-compose ps
----

If you run the command above, in the output’s "State" column, you’ll see information about the health check.
It will be one of three values:

* `health: starting`: This is the initial status when a container with a healthcheck is started. 
* `healthy`: The container is healthy
* `unhealthy`: The container is not working correctly

[INFO]
====
I’m not going into too much detail about healthchecks in this short guide. 
If you’re keen to know more about them, check out https://docs.docker.com/engine/reference/builder/#healthcheck[the documentation] for more information.
====

== The PHP Container

The configuration for the PHP container below is rather similar to that of the NGINX container.

[source,yaml]
----
php:
  build: ./docker/php/
  restart: always
  expose:
    - 9000
  volumes:
    - .:/var/www/html
----

You can see that it starts off by naming the container `php`, which sets the container's hostname.
The `build` directive tells it to use a configuration file, called `Dockerfile`, located in `./docker/php` which contains the following instructions:

[source,yaml]
----
FROM php:7.4-fpm

RUN docker-php-ext-install pdo_pgsql
----

This states that our container is based on the official PHP 7.4 image from Docker Hub, which uses PHP-FPM.
I'm keeping things as official as possible.

In addition to using the default image, I've also installed the PDO PostgreSQL extension, by calling the `docker-php-ext-install` command.

NOTE: This command does not install an extension's dependencies.
It only installs the extension, _if_ the dependencies are available.

Going back to docker-compose.yml, it next exposes the container's port 9000.
If this is your first time reading about Docker, that might not make a lot of sense.
It's a lot like when we allow access to a port through a firewall, only it’s only for container to container communication.

TIP: If you want to access a port on the container, you have to use the `ports` directive.

If you've had a look at `./docker/nginx/default.conf` in the source repository, you'll have seen that it contains the directive: `fastcgi_pass php:9000;`.
This allows the NGINX container to pass off requests to PHP in the PHP container.

Lastly, we're mapping a directory on our development machine to a directory in the container, for use in the container.
This has the effect of sharing your local directory with the container, rather like https://www.vagrantup.com/docs/synced-folders/[Vagrant's shared folders], which makes local development quite efficient.

When you make a change in your development environment, whether in a text editor, or an IDE such as PhpStorm, the changes will be available in the container as well.
There is no need to manually copy or sync files between your development environment and the container.

== The PostgreSQL Server

Now, for the final piece, the PostgreSQL container.

[source,yaml]
----
postgresql:
  image: postgres:13.1-alpine
  restart: always
  environment:
    POSTGRES_PASSWORD: project
    POSTGRES_USER: user
    POSTGRES_DB: project_db
  volumes:
    - ./data:/var/lib/postgresql/data
----

As with the other containers, we've given it a name (`postgresql`).
We are using https://hub.docker.com/_/postgres/[the official PostgreSQL image], from Docker Hub.
We’re not exposing a port, as we’re going to use https://www.adminer.org/[Adminer], a PHP front end administration tool, in another container to administer it.

TIP: If you prefer using psql, you can connect to the container and interact with the database that way.

Notice the `environment` option.
Here, we can pass environment variables to the container, ones which have been pre-defined.
We’re setting three environment variables.
These are for the database user’s username and password, and the database name.

[TIP]
====
You can find a list of the predefined variables for an image in the image’s official documentation, an example of which you can see in the image below.

image::...[]
====

Next, using the `volumes` directive, we're making any changes in `/var/lib/postgresql/data`, where PostgreSQL will store its data files, permanent, as they will be written to the local `data` directory in the project’s root.


[source,yaml]
----
adminer:
  image: adminer
  restart: always
  ports:
    - 8090:8080
  depends_on:
    - postgresql
----

Lastly, we’re adding one final container, for Adminer, so that, when necessary, we can administer the PostgreSQL server directly.
All but one of the directives you are now familiar with.

The new directive is `depends_on`. 
To this directive we can pass a list of container names which this container depends on.
When `docker-compose up` is run, the containers which this container depends on are started first. 
When `docker-compose down` is run, this container will be stopped before the containers on which it depends are stopped.

== Booting the Docker Containers

Now that we've configured the containers let's make use of them.
From the terminal, in the root directory of your project, run the following command:

----
docker-compose up -d
----

What this will do, is to look for `docker-compose.yml` in the same directory for the instructions it needs to build the containers, and then start them, based on the dependency order.
After they start, Docker will go into _detached_ mode, where the containers are run in the background.
When you run this, you'll see each container being created and started.

If this is the first time that you've created and launched the containers, then the base images will be downloaded before the containers can be created on top of them.
This may take a few minutes, based on the speed of your connection.
However, after the first time, they'll usually be booted in under a minute.

[TIP]
====
If you want to save yourself a bit of time, pull the respective base images down locally using `docker pull`, as you can see in the image below.

image::local-development-environment/official-image-documentation-example.png[The docker pull command example in the official Docker image documentation]
====

With them created, you're ready to use them.
At this point, in a browser, navigate to `http://localhost:8080`, where you'll see the application running. 
It renders https://matthewsetter.com/zend-expressive-introduction[the standard Mezzio Skeleton Project home page].
Nothing flash, but it works.

image::local-development-environment/official-image-documentation-example.png[The docker pull command example in the official Docker image documentation]

== Chapter Recap

That's how to use Docker to build a local development environment for a PHP application.
We have one container which runs PHP, one which runs NGINX, one which runs PostgreSQL, and one which runs Adminer;
All able to talk to each other as needed, and we can access NGINX on port 8080 of our local machine.

You could say that we can now build environments a lot like we can build code—in a modular fashion.
It's a fair way of thinking about it.
Why shouldn't we be able to do so?

I appreciate this has been quite a rapid run-through.
But it has covered the basics required to get you started.
We haven't looked _too_ deeply into how Docker works, nor gone too far beyond the basics.
However, we have covered the essentials.

== In the Next Chapter

Coming up in the next chapter, we’ll build on what you learned in this chapter, by stepping through how to debug a Docker Compose environment. 
See you then.
